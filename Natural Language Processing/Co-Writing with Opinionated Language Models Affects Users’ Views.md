## Co-Writing with Opinionated Language Models Affects Users’ Views

1. Propose an alternative title.
2. Discuss a missing experiment from the paper.
3. Submit a question about the paper.
4. What social or other impacts were overlooked or omitted?

**Alternative title:**
The Impact of Opinionated Language Models on User Opinions

**Missing Experiments from the paper:**
While the experiment involved three groups of people:

(1) Control group: participants wrote their answers without a writing assistant.
(2) Techno-optimist language model treatment: participants were shown suggestions from a language model configured to argue that social media is good for society.
(3) Techno-pessimist language model treatment: participants received suggestions from a language model configured to argue that social media is bad for society.

Adding a fourth group - participants shown suggestions from a model configured to find a balance between the pros and cons of social media - would have added more information to the experiment.

**Question About the Paper:**
How strongly will a model affect the opinion of users if it isn't strongly opinionated?
What will be the likely outcome if the experiment was carried out on a smaller set of participants but over an extended period of time?

**Social and Other Impacts overlooked:**
The publicizing of the effect of the influence of Large Language Models on the opinion of people might be exploited and directed towards specific people in sensitive cases like politics. It is possible that LLMs' influence could be used to sway certain individuals in specific situations, potentially leading to harmful outcomes.

**Limitations:**
Entire experiment was concluded using a specific LL model (GPT-3) and was constrained to a specific topic.

**Baseline:** Entire experiment was concluded using the GPT-3

Academic Researcher. You’re a researcher who is working on a new project in this area. Propose an imaginary follow-up project not just based on the current but only possible due to the existence and success of the current paper. (2 students, 5 min)

**Aim:** Investigation of the impact of highly generated opinions of LLMs on users' thought and writing.

**Findings:** Opinion built into AI languiage technologies need to be monitored. In latent persuasion, language models produce some opinions more often than others, influencing what their users write, which is, in turn, read by others.

**Potential ideas:**

- Running the experiment using multiple models for suggestions.
- Experimenting on participants over an extended period of time.
- Instead of using an entire model, we could use word by word suggestions or phrase by phrase suggestions.
- Model could suggest a number of pro and con sentences or ideas and we evaluate how these suggested ideas affect if the participant deviate from their initial stand before the typing starts.

U**S**er **A**ware cowri**T**ing with pr**O** and co**N** suggestion large language models

SATON LLM.

GPT-4 (OpenAI)
LaMDA (Google AI)
LLaMA (Meta AI)
PaLM (Google AI)
BARD (Google AI)
Claude v1 (Google AI)
